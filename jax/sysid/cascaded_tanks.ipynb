{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-linear regression with feedforward networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48032199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "import nonlinear_benchmarks\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.key(42)\n",
    "keys = jr.split(key, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d22338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = nonlinear_benchmarks.Cascaded_Tanks(atleast_2d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.u.shape, train.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f876c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sampling_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 6))\n",
    "plt.suptitle('Training (left) and test (right) data')\n",
    "train_t = train.sampling_time * jnp.arange(train.u.shape[0])\n",
    "ax[0, 0].plot(train_t, train.y)\n",
    "ax[1, 0].plot(train_t, train.u)\n",
    "test_t = train.sampling_time * jnp.arange(test.u.shape[0])\n",
    "ax[0, 1].plot(test_t, test.y)\n",
    "ax[1, 1].plot(test_t, test.u);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50eab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale data\n",
    "scaler_u = StandardScaler()\n",
    "u = scaler_u.fit_transform(train.u).astype(jnp.float32)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(train.y).astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same shapes as before...\n",
    "u.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2411192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... but normalized to zero mean and unit variance\n",
    "u.mean(), u.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all parameters and organize them in a dictionary\n",
    "\n",
    "nu = 1; nx = 2; ny = 1; nh = 16\n",
    "\n",
    "params_init = {\n",
    "  \"W1\": jr.normal(keys[0], shape=(nh, nu+nx)), # nu + nx inputs to the network\n",
    "  \"b1\": jr.normal(keys[1], shape=(nh,)),\n",
    "  \"W2\": jr.normal(keys[2], shape=(nx, nh)) * 1e-3, # nx outputs from the network\n",
    "  \"b2\": jr.normal(keys[3], shape=(nx,)) * 1e-3, \n",
    "\n",
    "  \"C\": jr.normal(keys[4], shape=(ny, nx)), # nx inputs and ny outputs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90642db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network as a function of parameters and inputs\n",
    "\n",
    "def fg(p, x, u):\n",
    "\n",
    "    # state update\n",
    "    xu = jnp.concatenate([x, u]) # vec(x, u)\n",
    "    z = jnp.tanh(p[\"W1\"] @ xu + p[\"b1\"])\n",
    "    x_new = x + p[\"W2\"] @ z + p[\"b2\"]\n",
    "\n",
    "    # output equation\n",
    "    y = p[\"C\"] @ x_new # linear output layer\n",
    "    return x_new, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to test it\n",
    "fg(params_init, jnp.zeros((nx,)), jnp.zeros((nu,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f976b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop implementation of the simulation\n",
    "x0 = jnp.zeros((nx,))\n",
    "\n",
    "x_step = x0\n",
    "y_sim = []\n",
    "for t in range(u.shape[0]):\n",
    "    x_step, y_step = fg(params_init, x_step, u[t])\n",
    "    y_sim.append(y_step)\n",
    "\n",
    "xf = x_step # final state after simulation\n",
    "y_sim = jnp.stack(y_sim, axis=0) # simulation output\n",
    "y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd199525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative implementation using jax.lax.scan (harder to read for the novice, but more efficient)\n",
    "\n",
    "# define funfunction with parameters p fixed\n",
    "def fg_p(x, u_t):\n",
    "    x_new, y = fg(params_init, x, u_t)\n",
    "    return x_new, y\n",
    "# Use scan to simulate over the entire input sequence\n",
    "xf, y_sim = jax.lax.scan(fg_p, x0, u)\n",
    "y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741979e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(p, x0, u):\n",
    "    x_step = x0\n",
    "    y_sim = []\n",
    "    for t in range(u.shape[0]):\n",
    "        x_step, y_step = fg(p, x_step, u[t])\n",
    "        y_sim.append(y_step)\n",
    "    y_sim = jnp.stack(y_sim, axis=0) # simulation output\n",
    "    return y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent implementation using jax.lax.scan (generally faster)\n",
    "def simulate_scan(p, x0, u):\n",
    "    def fg_func(x, u_t):\n",
    "        x_new, y = fg(p, x, u_t)\n",
    "        return x_new, y\n",
    "    xf, y_sim = jax.lax.scan(fg_func, x0, u)\n",
    "    return y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70247120",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_vars = {\n",
    "    \"params\": params_init,\n",
    "    \"x0\": jnp.zeros((nx,))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667344a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(ov, y, u):\n",
    "    y_sim = simulate(ov[\"params\"], ov[\"x0\"], u)\n",
    "    return jnp.mean((y - y_sim)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(opt_vars, y, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "lr = 1e-3\n",
    "iters = 5_000\n",
    "optimizer = optax.adam(learning_rate=lr)\n",
    "opt_state = optimizer.init(opt_vars)\n",
    "loss_grad_fn = jax.jit(jax.value_and_grad(loss_fn))\n",
    "\n",
    "# Training loop\n",
    "LOSS = []\n",
    "for iter in (pbar := tqdm(range(iters))):\n",
    "        loss_val, grads = loss_grad_fn(opt_vars, y, u)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        opt_vars = optax.apply_updates(opt_vars, updates)\n",
    "        LOSS.append(loss_val)\n",
    "        if iter % 100 == 0:\n",
    "            pbar.set_postfix_str(f\"Loss step {iter}: {loss_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09caaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = simulate(opt_vars[\"params\"], opt_vars[\"x0\"], scaler_u.transform(test.u).astype(jnp.float32))\n",
    "y_test_hat = scaler_y.inverse_transform(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test.y, \"k\")\n",
    "plt.plot(y_test_hat, \"b\")\n",
    "plt.plot(y_test_hat - test.y, \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2163689",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = jnp.sqrt(jnp.mean((y_test_hat - test.y)**2))\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
